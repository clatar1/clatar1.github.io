<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Halyun Jeong</title>
  </head>
<body>
    <div style="display: flex; align-items: center;">
        <!-- Left side: Text content -->
        <div style="flex: 1;">
            <h1>Halyun Jeong</h1>
            <p>
                University at Albany, SUNY<br>
                Email: hjeong2@albany.edu
            </p>
        </div>
        <!-- Right side: Portrait image -->
        <div style="flex: 0 0 auto; margin-left: 20px;">
            <img src="Halyun_photo.JPEG" alt="Portrait of Halyun Jeong" style="width: 180px; height: auto;">
        </div>
    </div>

    <p>
        I am an Assistant Professor in the Department of Mathematics & Statistics at SUNY Albany.
    </p>
    <p>
        Previously, I was an Assistant Adjunct Professor at UCLA, where my research mentor was 
        <a href="https://www.math.ucla.edu/~deanna/">Professor Deanna Needell</a>. Before that, I was a PIMS postdoctoral fellow at the University of British Columbia, working with 
        <a href="https://www.math.ubc.ca/~oyilmaz/">Ozgur Yilmaz</a>, 
        <a href="https://www.yanivplan.com/">Yaniv Plan</a>, and 
        <a href="https://friedlander.io/">Michael Friedlander</a>. I received my Ph.D. in Mathematics from the 
        Courant Institute of Mathematical Sciences at New York University in 2017 under the supervision of 
        <a href="https://cims.nyu.edu/~gunturk/">Sinan Gunturk</a>.
    </p>
  
    <h2>Research</h2>
    <p>
       My research interests span the mathematical aspects of machine learning and signal processing, specifically focusing on the structure of high-dimensional datasets and the convergence guarantees of both convex and non-convex methods that leverage such structures. 
    </p>
 
    <h2>Publications</h2>
<ul>

    <li>
    Linear Convergence of Reshuffling Kaczmarz Methods With Sparse Constraints, SIAM Journal on Scientific Computing, to appear
 <a href="https://arxiv.org/pdf/2304.10123.pdf"> [1st version arXiv link] </a> 
<br/>
(joint work with Deanna Needell)<br/>
   </li>
   <br/>

   <li>
   Stochastic gradient descent for streaming linear and rectified linear systems with adversarial corruptions, SIAM Journal on Mathematics of Data Science (SIMODS), 2025   
    <a href="https://epubs.siam.org/doi/abs/10.1137/24M1652167> [Journal link] </a>  <a href="https://arxiv.org/pdf/2403.01204"> [arXiv link] </a> 
<br/>
(joint work with Deanna Needell and 
<a href="https://erebrova.github.io"> Elizaveta Rebrova</a>)<br/>
   </li>
   <br/>

     <li>
   Robust Fourier Neural Network, Preprint  
    <a href="https://arxiv.org/pdf/2409.02052"> [arXiv link] </a> 
<br/>
(joint work with Jihun Han)<br/>
   </li>
   <br/>

   <li>
   Nearly Optimal Bounds for Cyclic Forgetting,  Neural Information Processing Systems (NeurIPS), 2023 
<br/>
(joint work with 
<a href="https://www.math.ucla.edu/~markkong"> Mark Kong</a>, 
<a href="https://wswartworth.github.io"> William Swartworth </a>, Deanna Needell, and 
<a href="https://www.rachelward.site"> Rachel Ward</a>)<br/>
   </li>
   <br/>

   <li>
    Federated Gradient Matching Pursuit, IEEE Transactions on Information Theory, 2024  <a href="https://ieeexplore.ieee.org/document/10495073?denied="> [journal link] </a> 
<br/>
(joint work with Deanna Needell and 
<a href="https://ms.uky.edu/~jqi229/"> Jing Qin</a>)<br/>
   </li>
   <br/>

   <li>
   Polar Deconvolution of mixed signals, IEEE Transactions on Signal Processing, 2022 <a href="https://ieeexplore.ieee.org/document/9783095"> [journal link] </a> 
<br/>
(joint work with Zhenan Fan, Babhru Joshi, and Michael P. Friedlander)<br/>
   </li>
   <br/>

  <li>
NBIHT: An Efficient Algorithm for 1-bit Compressed Sensing with Optimal Error Decay Rate, IEEE Transactions on Information Theory, 2022  <a href="https://ieeexplore.ieee.org/document/9597562"> [journal link] </a>
<br/>
(joint work with Michael P. Friedlander, Yaniv Plan, and Ozgur Yilmaz)<br/>
</li>
   <br/>

   <li>
Sub-Gaussian Matrices on Sets:  Optimal Tail Dependence and Applications, Communications on Pure and Applied Mathematics (CPAM), 2021 <a href="https://onlinelibrary.wiley.com/doi/10.1002/cpa.22024?af=R"> [journal link] </a>
<br/>
(joint work with Xiaowei Li, Yaniv Plan, and Ozgur Yilmaz)<br/>

   </li>
   <br/>

  
    <li> Atomic Decomposition Via Polar Alignment: The Geometry of Structured Optimization, Foundations and Trends in Optimization, Volume 3:280-366, 2020 <a href="https://www.nowpublishers.com/article/Details/OPT-028"> [journal link] </a> <a href="Polar_Alignment.pdf"> [pdf] </a>
<br/>
(joint work with Zhenan Fan, Michael P. Friedlander, and Yifan Sun)<br/>
    </li>
   <br/>

    <li> Non-Gaussian Random Matrices on Sets: Optimal Tail Dependence and Applications, Proceedings of International Conference on Sampling Theory and Applications (SampTA), 2019  
<br/>
(joint work with Xiaowei Li, Yaniv Plan, and Ozgur Yilmaz)<br/>
    </li>
   <br/>
 
    <li>  Are we there yet? Manifold identification of gradient-related proximal methods, Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS), 2019 
    <a href="http://www.optimization-online.org/DB_FILE/2019/03/7109.pdf"> link. </a>
<br/>
(joint work with  Yifan Sun, Julie Nutini, and Mark Schmidt)<br/>
</li> 
   <br/>

      <li> Convergence of the randomized Kaczmarz method for phase retrieval, 
      <a href="https://arxiv.org/abs/1706.10291"> Preprint. </a>
<br/>
(joint work with  Sinan Gunturk)<br/>

<!--
         </li>
      <li>Halyun Jeong, Thang Huynh, and C. Sinan Güntürk, Distributed
        noise-shaping quantization for phase retrieval, In preparation. 
      </li>
      <li>Halyun Jeong, Spectral analysis of ΣΔ modulation with
        dithering, In preparation.</li>
      <li> Halyun Jeong and Young-Han Kim, <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5205585"> Sparse linear representation </a>,
        Proceedings of the IEEE International Conference on Symposium on
        Information Theory (ISIT) - volume 1, 2009, pp. 329–333 </a>
arXiv: <a href="https://arxiv.org/abs/0905.1990">0905.1990 </a><p></li>
-->
    </ul>

    <h2>Recent Talks</h2>
<ul>
  <li>
[Jan 2025] Invited talk at Joint Mathematics Meetings AMS Special Session.
   <li>
[Oct 2024] Invited talk at AMS Fall Eastern Sectional Meeting.
   <li>
[May 2024] Invited talk at SIAM Conference on Applied Linear Algebra 24 minisymposium. 
   </li>
   <li>
[April 2024] Invited talk at the Applied Mathematics Seminar at the University of California, Irvine. 
   </li>
</ul>
    <h2>Teaching at SUNY Albany</h2>
<ul> 
     AMAT 554 Introduction to Theory of Statistics I  </p>
</ul>
</ul>
    <h2>Teaching at UCLA</h2>
<ul> 
     Math156 Machine Learning  </p>
     Math151B Numerical methods  </p>
     Math170E Probability and Statistics: Probability  </p>
     Math170S Probability and Statistics: Statistics  </p>
</ul>
    <h2>Teaching at UBC</h2>
<ul> 
    <p>Winter 2019 Term 2: <a href="MATH307_2019W2.html">
     Math307 (Applied linear algebra) </a> </p>
    <p>Winter 2018 Term 2: <a href="MATH221_2018W2.html">
     Math221 (Matrix algebra) </a> </p>
    <p>Winter 2018 Term 1: <a href="Math307_2018W1.html">
     Math307 (Applied linear algebra) </a> </p>
    <p>Winter 2017 Term 1: <a href="Math307Winter.html">
     Math307 (Applied linear algebra) </a> </p>
</ul>
    <h2>Teaching at NYU</h2>
<ul> 
    <p>Fall 2016: Calculus 1 recitation</p>
    <p>Fall 2015: Honors III (Fourier analysis) recitation </p>
    <p>Fall 2014: Algebra and Calculus (Precalculus) recitation</p>
</ul>
  </body>
<a/html>
